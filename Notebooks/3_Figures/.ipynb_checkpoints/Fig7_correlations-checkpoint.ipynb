{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to plot figure 9: model and proxy correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "#Input Data: \n",
    "modelDataPath = 'Data/Model/' #netcdf of model data. Unique my model/season. Each contains multiple climate variables\n",
    "proxyCorrPath = 'Data/RegionComposites/'\n",
    "#Load Packages\n",
    "import cartopy.crs         as ccrs\n",
    "import cartopy.util        as cutil\n",
    "import cmasher as cmr\n",
    "import matplotlib.pyplot   as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from   matplotlib.colors   import LinearSegmentedColormap\n",
    "import numpy               as np\n",
    "import os\n",
    "import pandas              as pd \n",
    "import regionmask          as rm\n",
    "from   scipy.stats         import pearsonr \n",
    "import warnings\n",
    "import xarray              as xr\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "refReg    = rm.defined_regions.ar6.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/chrishancock/Library/CloudStorage/OneDrive-NorthernArizonaUniversity/Research/Manuscript/HoloceneHydroclimate/HoloceneHydroclimate\n"
     ]
    }
   ],
   "source": [
    "#Set Working Directory\n",
    "wd = '/Users/chrishancock/Library/CloudStorage/OneDrive-NorthernArizonaUniversity/Research/Manuscript/HoloceneHydroclimate/HoloceneHydroclimate'\n",
    "os.chdir(wd)\n",
    "print('Working directory set to: '+wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings chosen to save ['ANN'] pre vs tas\n"
     ]
    }
   ],
   "source": [
    "#Plot Agreement Settings\n",
    "\n",
    "#Model Data to Plot\n",
    "times = [0,12]\n",
    "seasons   = ['ANN']\n",
    "#m_1 = 'hadcm'\n",
    "v_1   = 'pre'\n",
    "v_2   = 'tas'\n",
    "regrid = True\n",
    "\n",
    "#True/False to save/not save\n",
    "save = True \n",
    "\n",
    "#Plot Settings\n",
    "font = 'Times New Roman'\n",
    "plt.rcParams['font.family'   ] = font\n",
    "plt.rcParams['axes.facecolor'] ='white'\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['axes.edgecolor'] = 'k'\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "#Print summary\n",
    "if save: print(\"Settings chosen to save \"+str(seasons)+\" \"+v_1+\" vs \"+v_2)\n",
    "else:    print(\"Settings chosen to plot \"+str(seasons)+\" \"+v_1+\" vs \"+v_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hadcm ['evp_regrid', 'p-e_regrid', 'pre_regrid', 'tas_regrid'] loaded\n",
      "trace ['evp_regrid', 'p-e_regrid', 'pre_regrid', 'tas_regrid'] loaded\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "#Proxy data calculated using geoChronR::corEns in Fig9_analysis_proxyCorEns\n",
    "\n",
    "if times == [0,12]:\n",
    "    proxy = pd.read_csv(proxyCorrPath+'HC_T_RegionalProxyEnsCorrelations.csv')\n",
    "else: #If Not the full holocene just use the 50% median\n",
    "    regions = []\n",
    "    proxyCorr= []\n",
    "    proxyHC = pd.read_csv(wd+'/Data/RegionComposites/HC/MedianTS_byRegion.csv')[times[0]*10:times[1]*10+1]\n",
    "    proxyT = pd.read_csv(wd+'/Data/RegionComposites/T/MedianTS_byRegion.csv')[times[0]*10:times[1]*10+1]\n",
    "    for reg in proxyHC.keys()[1:]:\n",
    "        if reg in proxyT.keys():\n",
    "            x = np.array(proxyHC[reg])\n",
    "            y = np.array(proxyT[reg])\n",
    "            nans = ~np.logical_or(np.isnan(x), np.isnan(y))\n",
    "            regions.append(reg)\n",
    "            proxyCorr.append(round(pearsonr(np.compress(nans, x),np.compress(nans, y))[0],4))\n",
    "    proxy = pd.DataFrame(proxyCorr).transpose()\n",
    "    proxy.columns = regions\n",
    "        \n",
    "refReg    = rm.defined_regions.ar6.all\n",
    "\n",
    "modelData = {}\n",
    "for model in ['hadcm','trace']:\n",
    "    modelData[model] = {}\n",
    "    for szn in seasons:\n",
    "        if regrid: end = '_regrid.nc'\n",
    "        else:      end =  '.nc'\n",
    "        modelData[model][szn] = xr.open_dataset(modelDataPath+model+'/'+model+'_'+szn+end,decode_times=False)\n",
    "    print(model+\" \"+str(sorted([i for i in modelData[model][szn].data_vars]))+' loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Created\n"
     ]
    }
   ],
   "source": [
    "#Define Function for calculating grid cell correlation values\n",
    "\n",
    "def calcCorrelation (inData,model1,model2,var1,var2,season,t0=0,t1=12,mask=False,regrid=True):\n",
    "    if regrid == False:\n",
    "        modelData1 = inData[model1][season][var1][t0*10:t1*10+1,:,:]\n",
    "        modelData2 = inData[model2][season][var2][t0*10:t1*10+1,:,:]\n",
    "        lats,lons = modelData1.lat,modelData1.lon\n",
    "    else: \n",
    "        modelData1 = inData[model1][season][var1+'_regrid'][t0*10:t1*10+1,:,:]\n",
    "        modelData2 = inData[model2][season][var2+'_regrid'][t0*10:t1*10+1,:,:]\n",
    "        lats,lons = modelData1.lat,modelData1.lon\n",
    "    t_0 = np.argmin(np.abs(t0*1000 - modelData1.age.data))   \n",
    "    t_1 = np.argmin(np.abs(t1*1000 - modelData1.age.data))\n",
    "    out = np.full(np.shape(modelData1)[1:3],np.NaN)\n",
    "    for lat in range(len(lats)):\n",
    "        for lon in range(len(lons)):\n",
    "            out[lat,lon] = pearsonr(modelData1[t_0:t_1,lat,lon].data,modelData2[t_0:t_1,lat,lon].data)[0]\n",
    "    return(out)\n",
    "\n",
    "print('Function Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating model correlations...This might take a minute or two to calculate for all grid cells...\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "#Calculate using function\n",
    "print(\"Calculating model correlations...This might take a minute or two to calculate for all grid cells...\")\n",
    "      \n",
    "#rVals = calcCorrelation(modelData,m_1,m_2,v_1,v_2,szn,times[0],times[1])\n",
    "rVals1 = calcCorrelation(modelData,'hadcm','hadcm',v_1,v_2,szn,times[0],times[1])\n",
    "print(\"...\")\n",
    "rVals2 = calcCorrelation(modelData,'trace','trace',v_1,v_2,szn,times[0],times[1])\n",
    "rVals  = np.mean([rVals2,rVals1],axis=0)\n",
    "\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if times == [0,12]:\n",
    "    if save: \n",
    "        np.savetxt('Data/Model/hadcm/transCorr_P_T_hadcm.csv', rVals1, delimiter=\",\")\n",
    "        np.savetxt('Data/Model/trace/transCorr_P_T_trace.csv', rVals2, delimiter=\",\")\n",
    "        print(\"csv of r values saved\")\n",
    "    else: print(\"did not save r values as csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define proxy correlations for each region\n",
    "pltRegs, pltVals, pltlats, pltlons, = [],[],[],[]\n",
    "for reg in proxy.columns.values.tolist()[1:]: \n",
    "    pltVals.append(np.nanmean(proxy[reg]))\n",
    "    pltlats.append(refReg.centroids[refReg.abbrevs.index(reg)][1])\n",
    "    pltlons.append(refReg.centroids[refReg.abbrevs.index(reg)][0])\n",
    "    pltRegs.append(reg) \n",
    "    #\n",
    "print(\"Proxy Data Ready to Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set Color Settings\n",
    "cramp   = LinearSegmentedColormap.from_list('cramp',['#40004b','white','#00441b'],N=30)\n",
    "cramp   = cmr.get_sub_cmap(cramp,0.1,0.9,N=20)\n",
    "mlevels = np.array([i /10 for i in list(range(-10,11,2))])\n",
    "m_1='trace'\n",
    "#Set Lat/Lons\n",
    "lats,lons = modelData[m_1][szn]['lat'],modelData[m_1][szn]['lon']\n",
    "if regrid: name      = 'multi'+'_'+v_1+'_'+v_2+'_'+szn+'_'+str(times[0])+'to'+str(times[1])+'ka'\n",
    "else: name      = m_1+'_'+v_1+'_'+v_2+'_'+szn+'_'+str(times[0])+'to'+str(times[1])+'ka'\n",
    "    \n",
    "#Plot\n",
    "plt.figure(figsize=(6,3.01))\n",
    "gs = gridspec.GridSpec(12,8)\n",
    "ax0 = plt.subplot(gs[0:12,0:6],projection=ccrs.Robinson()) \n",
    "rm.defined_regions.ar6.land.plot_regions(ax=ax0,add_label=False,line_kws=dict(linewidth=0.7))\n",
    "data_cyclic,lon_cyclic = cutil.add_cyclic_point(rVals,coord=lons)\n",
    "model_contour = plt.contourf(lon_cyclic,lats, data_cyclic,transform=ccrs.PlateCarree(),vmin=-1,vmax=1,cmap=cramp,levels=20)  \n",
    "ax0.set_global()\n",
    "ax0.scatter(pltlons,pltlats,c=pltVals,transform=ccrs.PlateCarree(),cmap=cramp,vmin=-1,vmax=1,s=40,ec='k',lw=2)\n",
    "ax0.annotate('(a)',xy=(0, 0), xycoords='data', xytext=(0.05, 0.95), \n",
    "            textcoords='axes fraction', fontsize=8, fontfamily = font)\n",
    "cbar = plt.colorbar(model_contour,orientation=\"horizontal\",ticks=[-1,-0.6,-0.3,0,0.3,0.6,1],\n",
    "                        fraction=0.04, pad=0.04,aspect=30)\n",
    "cbar.set_label('Pearson Correlation Coefficient',fontsize=8, fontfamily = font)\n",
    "cbar.ax.set_xticklabels([-1,-0.6,-0.3,0,0.3,0.6,1],fontsize=8)\n",
    "\n",
    "\n",
    "mask = rm.defined_regions.natural_earth.land_110.mask_3D(lons,lats).squeeze('region').data\n",
    " \n",
    "ax1 = plt.subplot(gs[2:11,6:8]) \n",
    "rValsLand = np.full(np.shape(rVals),np.NaN) \n",
    "for lat in range(len(lats)):\n",
    "    for lon in range(len(lons)):\n",
    "        if mask[lat,lon]: rValsLand[lat,lon] = rVals[lat,lon]\n",
    "ax1.annotate('(b)',xy=(0, 0), xycoords='data', xytext=(-0.2, 0.95), \n",
    "            textcoords='axes fraction', fontsize=8, fontfamily = font)\n",
    "ax1.axvline(x=0,color='black',lw=0.5)\n",
    "for i in range(-90,91,30):\n",
    "    ax1.axhline(y=i,xmin=0,xmax=0.05,color='grey',lw=0.3)\n",
    "    ax1.axhline(y=i,xmin=0.95,xmax=1,color='grey',lw=0.3)\n",
    "\n",
    "ax1.axis([mlevels[0],mlevels[-1],lats[-2],lats[1]])\n",
    "\n",
    "x = np.nanmean(rValsLand, axis=1) \n",
    "ax1.plot(np.nanmean(rVals,axis=1) ,lats,c='darkslategrey',lw=1.9,label='All grid cells')\n",
    "ax1.plot(x,lats,'-',c='darkgoldenrod',lw=1.9,label='Land grid cells')\n",
    "ax1.scatter(pltVals,pltlats,c='k',s=7)#plt.cm.get_cmap('BrBG',5),\n",
    "#ax1.spines['right'].set_visible(False);ax1.spines['left'].set_visible(False)\n",
    "ax1.invert_yaxis() \n",
    "ax1.set_yticklabels([-1,0,1],fontsize=8)\n",
    "ax1.set_yticks([])\n",
    "ax1.set_yticklabels([])\n",
    "#\n",
    "ax1.annotate('60'+u'\\N{DEGREE SIGN}'+'S',xy=(0, 0), xycoords='data', xytext=(1.02, 0.135), \n",
    "            textcoords='axes fraction', fontsize=8, fontfamily = font)\n",
    "ax1.annotate('30'+u'\\N{DEGREE SIGN}'+'S',xy=(0, 0), xycoords='data', xytext=(1.02, 0.305), \n",
    "            textcoords='axes fraction', fontsize=8, fontfamily = font)\n",
    "ax1.annotate('0'+u'\\N{DEGREE SIGN}',     xy=(0, 0), xycoords='data', xytext=(1.02, 0.48), \n",
    "            textcoords='axes fraction', fontsize=8, fontfamily = font)\n",
    "ax1.annotate('30'+u'\\N{DEGREE SIGN}'+'N',xy=(0, 0), xycoords='data', xytext=(1.02, 0.65), \n",
    "            textcoords='axes fraction', fontsize=8, fontfamily = font)\n",
    "ax1.annotate('60'+u'\\N{DEGREE SIGN}'+'N',xy=(0, 0), xycoords='data', xytext=(1.02, 0.825), \n",
    "            textcoords='axes fraction', fontsize=8, fontfamily = font)\n",
    "#\n",
    "plt.legend(loc='lower center',fontsize=8,bbox_to_anchor=(0.5, -0.4))\n",
    "\n",
    "#Save or show\n",
    "if save: \n",
    "    plt.savefig('Figures/Model/TransientCorrelations/'+name+'.png', dpi=600,format='png', bbox_inches='tight')  \n",
    "    print(\"plot saved\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
