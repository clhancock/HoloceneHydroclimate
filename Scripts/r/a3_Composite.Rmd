---
goal: create regional composits based on ipcc regions. works with either temp or hc
input: LiPD files, csv file from python script to filter TSids with
output: individual csv for each region where columns repersent iterations. Also summary with each column as the regional median timeseries
---
#Changed minN from 8 to 3 in standardize function to accomodate lake deposits
#   this is the number of measurments neaded to be located withing the search range

setwd(githubDir)
###Settings in script
```{r}
#Set up directories and names
#dataDir   <- '/Volumes/GoogleDrive/My Drive/zResearch/Data/'
githubDir <- '/Volumes/GoogleDrive/My Drive/zResearch/HoloceneHydroclimate'
#dataDir   <- 'G:/My Drive/zResearch/Data/'
githubDir <- 'G:/My Drive/zResearch/HoloceneHydroclimate/'
setwd(githubDir)
#
```

```{r}
library(geoChronR)
library(lipdR)
#library(scales)
#library(cowplot)
library(purrr)
library(dplyr)
library(magrittr)
#library(ggplot2)
library(compositeR)
library(foreach)
library(doParallel)
#library(abind)
#library(ncdf4)
```

###Load Data
```{r}
lipdData <- readRDS(file.path(githubDir,'Data','LiPD','lipdData.rds'))
Save <- TRUE

climVar <- 'HC'
lipdTSO <- lipdData[[climVar]]
regionNames <- sort(unique(as.character(pullTsVariable(lipdTSO,'geo_ipccRegion'))))
```


```{r message=FALSE} 
#set.seed(#) Set same sets of records which will make completely reproducable
#
#Set variables for composite code
nens          <- 200  #make low to run quickly, set high to get large ensemble range (variation from standardization search range and order )
binsize       <- 200 #years
ageMin        <- 0 #age BP
ageMax        <- 12000 #age BP
searchAgeMin  <- 0 #age BP
searchAgeMax  <- 8000 #age BP
searchDuration<- 3500 #yrs
minNrecords   <- 6 #num of records
#
binvec   <- seq(ageMin-binsize/2, to = ageMax+binsize/2, by = binsize)
binYears <- rowMeans(cbind(binvec[-1],binvec[-length(binvec)]))

#Set up data to add once
compositeEns      <- vector(mode="list")
medianCompositeTS <- data_frame(time=binYears)
    
for (region in regionNames) {
  #Filter the TS by cluster name and make sure have enough values
  lipdRegion <- filterTs(lipdTSO,paste('geo_ipccRegion ==',region))
  #Skip if number of records is too few
  if(length(lipdRegion)<minNrecords|sum(pullTsVariable(lipdRegion,'archiveType')!="LakeDeposits")<=2)next
  #
  #setup and run ensemble ########## This is the main part of the code to edit ##########
  compEns <- matrix(NA,nrow = length(binYears),ncol=nens)
  for (i in 1:nens){
    tc <- compositeR::compositeEnsembles(lipdRegion,
                             binvec,
                             stanFun = standardizeMeanIteratively,
                             minN = 3,
                             ageVar  = "age",
                             alignInterpDirection = TRUE,
                             spread      = TRUE,
                             duration    = searchDuration,
                             searchRange = c(searchAgeMin,searchAgeMax),
                             normalizeVariance = TRUE,
                             scope = "climate",
                             binFun = simpleBinTs) #sampleEnsembleThenBinTs
    compEns[,i] <- tc$composite
  }
  #
  # Return reconstruction and additional data for plotting
  compositeEns[[region]]      <- compEns
  medianCompositeTS[[region]] <- apply(compEns,1,median)
}




write.csv(medianCompositeTS, row.names = FALSE,
          file = file.path(githubDir,'Data','RegionComposites',climVar,'MedianTSbyRegion.csv'))

for (region in names(compositeEns)){
  write.csv(compositeEns[[region]], row.names = FALSE,
            file = file.path(githubDir,'Data','RegionComposites',climVar,paste(region,'.csv',sep='')))
            
}

print("csv files saved")
```

