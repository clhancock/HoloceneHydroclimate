#Load packages
#import pyleoclim as pyleo               # Packages for analyzing LiPD files 
#import lipd                             # Packages for analyzing LiPD files 
import numpy  as np                     # Package with useful numerical functions
import xarray as xr                     #Package for handling file types
import pandas as pd
#import math
from scipy import stats                 # Packages for calculations  
import pymannkendall as mk              # Package for trend detection
import matplotlib.pyplot as plt         # Packages for making figures
#import matplotlib as mpl 
#import matplotlib.gridspec as gridspec
#import matplotlib.colors as pltcolors
#from mpl_toolkits.axes_grid1.inset_locator import inset_axes
import cartopy.crs as ccrs              # Packages for mapping in python
import cartopy.feature as cfeature
#import cartopy.util as cutil
#
dataDir='/Volumes/GoogleDrive/My Drive/zResearch/Data/'
save=False
gitHub ='/Volumes/GoogleDrive/My Drive/zResearch/HoloceneHydroclimate/'
data_HC =  pd.read_csv(gitHub+'DataSummary/proxyHC.csv')
#%%
def calcTrend(timeValues,proxyValues,ageMin,ageMax,direction):    
    divisions = 2; minset = 3; sigLevel = 0.05; CI = 0.95; method = 'lin'
    if len(proxyValues) < 12: minset = 2
    ageRange = (ageMax - ageMin)/divisions
    valuedata = pd.DataFrame([timeValues,proxyValues]).transpose()
    valuedata.columns = ['time','values']
    valuedata = valuedata.loc[(valuedata['time'] <= ageMax) & (valuedata['time'] >= ageMin)]
    valuedata = valuedata.dropna() 
    check = []    
    for timeperiod in range(divisions):
        checkValue = len(valuedata.loc[(valuedata['time'] <= ageMin+(timeperiod+1)*ageRange) 
                                     & (valuedata['time'] >= ageMin+(timeperiod)*ageRange)]['time'])
        if checkValue >= minset: check.append(True)
        else: check.append(False)   
    if check.count(True) == divisions:
        valuedata['time']   = valuedata['time']*-1 #To get correct forward direction
        valuedata['values'] = valuedata['values']*direction
        trendDirection = mk.original_test(valuedata['values']*-1,alpha=sigLevel)
        if   method == 'lin': Slope = stats.linregress( valuedata['time'],valuedata['values'])
        elif method == 'sen': Slope = stats.theilslopes(valuedata['values'],valuedata['time'],CI)
        output = {'Direction':trendDirection[0],'Slope':Slope[0]*1000}
        if output['Direction'] == 'no trend': output['SlopeSig'] = 0
        else:                                 output['SlopeSig'] = output['Slope']
    else: output = {'Direction':np.NaN, 'Slope':np.NaN, 'SlopeSig':np.NaN}
    return(output)
#%%
#Load Model Data
#
#Set time variables and resolution of data
ageMin=0; ageMax=12000; ageRes=100
timebin = [*range(ageMin,ageMax+1,ageRes)]

#Model variable names and conversion to common time/variable units (generally mm/day)
modelKey = {'trace':{'lat':'lat','lon':'lon',
                     'Time':{'varName':'time','conversion':[-1000,0]}, #To 0-12ka Holocene
                     'Precip':{'varName':'PRECT','conversion':[(60*60*24*1000),0]}, #converts m/s to mm/day
                     'Evap':{'varName':'QFLX','conversion':[((1/1000)*(60*60*24*1000)),0]}, #converts kg/m2/s to m/s to mm/day
                     'Temp':{'varName':'TREFHT','conversion':[1,-273.15]}}, #converts K to degC
            'hadcm':{'lat':'latitude','lon':'longitude',
                     'Time':{'varName':'t','conversion':[-1,2000]}, #To 0-12ka Holocene
                     'Precip':{'varName':'precip_mm_srf','conversion':[((1/1000)*(60*60*24*1000)),0]}, #converts kg/m2/s to m/s to mm/day
                     'Evap':{'varName':'totalEvap_mm_srf','conversion':[1,0]}, #already in mm/day
                     'Temp':{'varName':'temp_mm_1_5m','conversion':[1,-273.15]}}} #converts K to degC
dataModel = {}
for model in modelKey.keys():
    dataModel[model] = {}
    for variable in ['Precip','Evap']: #',Temp'
        dataModel[model][variable] = {}
        for season in ['ANN','DJF','JJA']:
             print(model+variable+season)
             #Load data
             filename = modelKey[model][variable]['varName']
             if model == 'hadcm': filename = 'deglh.vn1_0.'+filename+'.monthly.'+season
             elif model=='trace': filename = 'trace.01-36.22000BP.cam2.'+filename+'.22000BP_decavg'+season+'_400BCE'
             data = xr.open_dataset(dataDir+'Model/'+model+'/'+filename+'.nc',decode_times=False)
             #For first climate variable, add lat/lon information 
             if len(dataModel[model]) == 1: 
                 dataModel[model]['lat']  = data[modelKey[model]['lat']].values
                 dataModel[model]['lon']  = data[modelKey[model]['lon']].values
                 dataModel[model]['lon']  = xr.where(dataModel[model]['lon'] > 180,dataModel[model]['lon'] - 360,dataModel[model]['lon'])
                 dataModel[model]['time'] = timebin
             #Convert to common time units
             modeltime   = data[modelKey[model]['Time']['varName']]
             modeltime   = modeltime.values*(modelKey[model]['Time']['conversion'][0])+modelKey[model]['Time']['conversion'][1] 
             #Convert to common variable units (mm/day typically)
             modelvalues = data[modelKey[model][variable]['varName']]
             modelvalues = modelvalues.values*(modelKey[model][variable]['conversion'][0])+modelKey[model][variable]['conversion'][1]              
             #Convert to common data structure
             if model == 'hadcm': modelvalues = modelvalues[:,0,:,:]
             #Bin data to common time resolution 
             modelvalues = pd.DataFrame([list(modeltime),list(modelvalues)]).transpose() 
             modelvalues.columns = ['time','values']
             binvalue = []
             for timeslice in timebin: binvalue.append(np.mean(modelvalues.loc[(modelvalues['time'] >= timeslice-ageRes/2) & (modelvalues['time'] < (timeslice+ageRes/2))]['values']))
             dataModel[model][variable][season] = np.dstack(binvalue)
    #
    #Calculate P-E
    dataModel[model]['EffM'] = {}
    for season in ['ANN','DJF','JJA']:
        dataModel[model]['EffM'][season] = dataModel[model]['Precip'][season] - dataModel[model]['Evap'][season] 
#
#%%
#def plotModelValues(model,season='ANN',variable='Precip'):

    
#%%

#%%
#Calc model pesuodporxy timeseries based on location, season, length, variable
#
setTime = {'Total':{'min':ageMin,                  'max':ageMax},
           'Early':{'min':ageMin+(ageMax-ageMin)/2,'max':ageMax},
           'Late' :{'min':ageMin,                  'max':ageMin+(ageMax-ageMin)/2}}
#ageMin,ageMax,ageRes

def calculatePseudoProxy(proxyDF,
                         dataModelDict=dataModel,
                         climVar='HC',#Or T # Change to 'P' or 'P-E' to test assumptions about proxies
                         seasonality='Proxy', # Change to 'ANN' or 'Summer' to test assumptions about proxies
                         standardize=True, #Will calculate z scores for records relative to Holocene timeseries
                         binRes=1000):
    output={}
    for model in dataModelDict.keys():
            pseudoproxy={}
            names_key    = ['TSid','Lat','Lon','Category','CategorySpecific','Interp']
            variable_key = ['Direction','Slope','SlopeSig']
            pseudoproxy['modelTS'] = []
            #Set up dictionary lists to add to 
            for time in setTime:  
                for var in variable_key: pseudoproxy[time+var] = []
            for name in names_key: pseudoproxy[name] = [] 
            for age in range(ageMin,ageMax,binRes): 
                pseudoproxy['bin'+str(int(age/binRes))+'ka'] = []
            #Populate data from model values
            for index, site in proxyDF.iterrows():
                #Add metadata
                for name in names_key: pseudoproxy[name].append(site[name])
                #ID seasonality from proxy metadata
                if   seasonality == 'ANN':      season = 'ANN' #assume everying annual 
                elif seasonality == 'Summer': #summer or annual are summer
                    if site['Season'] == 'winterOnly':
                        if site['Lat'] > 0:     season = 'DJF'
                        else:                   season = 'JJA'
                    else: 
                        if site['Lat'] > 0:     season = 'JJA'
                        else:                   season = 'DJF'
                else: #Use proxy metadata
                    if site['Season'] == 'summerOnly': 
                        if site['Lat'] > 0:     season = 'JJA'
                        else:                   season = 'DJF'
                    if site['Season'] == 'winterOnly':
                        if site['Lat'] > 0:     season = 'DJF'
                        else:                   season = 'JJA'
                    else: season = 'ANN'
                #ID appropriate climate variable for pseudoproxy
                if   climVar == 'T':          variable = 'Temp'
                elif climVar == 'HC':
                    if site['Interp'] == 'P': variable = 'Precip'
                    else:                     variable = 'EffM'
                elif climVar == 'P':          variable = 'Precip'
                elif climVar == 'P-E':        variable = 'EffM'
                #ID Model grid Location for proxy site
                lat=np.argmin(np.abs(dataModel[model]['lat']-site['Lat']))
                lon=np.argmin(np.abs(dataModel[model]['lon']-site['Lon']))
                #Standardize and get age range
                modelvalues = dataModel[model][variable][season][lat,lon,:]
                if standardize: modelvalues = stats.zscore(modelvalues)
                mask = [idx for idx, val in enumerate(dataModel[model]['time']) if (val < site['ageMin'] or val > site['ageMax'])]
                modelvalues[mask] = np.NaN
                #if len(pseudoproxy['modelTS']) < 1:
                pseudoproxy['modelTS'].append(list(modelvalues))
                #Calculate trends
                for time in setTime:   
                    out = calcTrend(dataModel[model]['time'],list(modelvalues),setTime[time]['min'],setTime[time]['max'],1)               
                    for var in variable_key: 
                        pseudoproxy[time+var].append(out[var])
                mask = [idx for idx, timeval in enumerate(dataModel[model]['time']) if timeval >= 0 and timeval <= 1000]
                lipdTS_std = np.nanmean(modelvalues[mask])
                #Calcaulte Bin values
                for age in range(ageMin,ageMax,binRes):
                    mask = [idx for idx, val in enumerate(dataModel[model]['time']) if val >= age and val < age+ageRes]
                    value_ts = np.nanmean(modelvalues[mask])
                    pseudoproxy['bin'+str(int(age/binRes))+'ka'].append((value_ts-lipdTS_std))
            output[model] = pd.DataFrame.from_dict(pseudoproxy)
    return(output)

#modelHC    = calculatePseudoProxy(data_HC)
#%%

modelProxies = {}
for Season in ['Proxy','Ann','Summer']:
    for climateInterp in ['HC','P','P-E']:
        name = climateInterp+'_'+Season
        modelProxies[name] = calculatePseudoProxy(data_HC,
                                                  climVar=climateInterp,
                                                  seasonality=Season)
        if save:
            for model in modelProxies[name].keys():
                modelProxies[name][model].to_csv(gitHub+'DataSummary/'+model+'_Pseudoproxy_'+name+'.csv')

#%%


