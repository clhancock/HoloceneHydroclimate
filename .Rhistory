}
for (name in metadata){
print(paste("Revised",name,":",list(unique(pullTsVariable(lipdData$HC,name)))))
}
#
for (var in c('HC')){
for (ts in 1:length(lipdData[[var]])){
#
#Load basic information for each record
#
tso     <- lipdData[[var]][[ts]]
Dselect <- D_hc[[tso$dataSetName]]
n_chron <- length(Dselect[["chronData"]][[1]][["measurementTable"]])
n_paleo <- max(length(Dselect[["paleoData"]]),length(Dselect[["paleoData"]][[1]][["measurementTable"]]))
#
#
if (n_chron == 0){
i_chron <- NA
} else if (n_chron*n_paleo == 1){
i_chron <- 1
} else if (grepl("Composite",tso$paleoData_variableName)){
offset<-c()
for (j in 1:n_chron){
chronAges <- Dselect[["chronData"]][[1]][["measurementTable"]][[j]][["age"]]$values
offset <- c(offset,max(abs(tso$ageMin-min(chronAges,na.rm=TRUE)),
abs(tso$ageMax-max(chronAges,na.rm=TRUE))))
}
i_chron <- which(offset==min(offset))
} else if(n_chron+1 == n_paleo & tso$archiveType=='Speleothem'){
for (i in 1:n_paleo){
if (!is.null(Dselect[["paleoData"]][[1]][["measurementTable"]][[i]][[tso$paleoData_variableName]]$TSid)){
if (Dselect[["paleoData"]][[1]][["measurementTable"]][[i]][[tso$paleoData_variableName]]$TSid == tso$paleoData_TSid){
i_chron <- i
}
}
}
} else if (n_chron != n_paleo){
offset<-c()
for (j in 1:n_chron){
chronAges <- Dselect[["chronData"]][[1]][["measurementTable"]][[j]][["age"]]$values
offset <- c(offset,max(abs(tso$ageMin-min(chronAges,na.rm=TRUE)),
abs(tso$ageMax-max(chronAges,na.rm=TRUE))))
}
i_chron <- which(offset==min(offset))
} else{
for (i in 1:n_paleo){
if (!is.null(Dselect[["paleoData"]][[1]][["measurementTable"]][[i]][[tso$paleoData_variableName]]$TSid)){
if (Dselect[["paleoData"]][[1]][["measurementTable"]][[i]][[tso$paleoData_variableName]]$TSid == tso$paleoData_TSid){
i_chron <- i
}
}
}
}
if (tso$paleoData_TSid %in% c('lcRpbhIeSqLqRxKnBNF','lcRseG41EyZPFn7vBuL','LPD1498ea89','LPD03892251')){i_chron<-NA}
if (!is.na(i_chron)){
tso$chronData_table <- Dselect[["chronData"]][[1]][["measurementTable"]][[i_chron]]
names <- names(tso$chronData_table)[grepl(c('age'),names(tso$chronData_table),ignore.case=TRUE)]
for (name in c('type','error','min','max','hi','radio','14','lo','comment','use',"up","old","young","std",
"reservoir","σ","low","Rejected","±","comment","err","uncertainty","unc")){
names <- names[which(grepl(name,names,ignore.case=TRUE)==FALSE)]
}
ageColName <- NA
for (name in c("Th230/Th232","Median","calib.14C","14C.raw","14C Age","14C age BP","Cal yr chosen","age14C","14C age (yr BP)","C14 age dated",
tail(names,1),"corrected 230Th Age",
"Median Year BP",'age','Age','calAge','CalAge','CalibratedAge','Calibrated Age')){
if (name %in% names(tso$chronData_table)){
ageColName <- name
}
}
tso$chronData_ageName <- ageColName
tso$chronData_ages <- as.numeric(tso$chronData_table[[tso$chronData_ageName]]$values)
if (grepl("Composite",tso$paleoData_variableName)){
tso$chronData_ages <- c()
for (j in 1:n_chron){
tso$chronData_ages <- c(tso$chronData_ages,as.numeric(Dselect[["chronData"]][[1]][["measurementTable"]][[j]][["age"]]$values))
}
}
if ((length(which(tso$chronData_ages<13000))<=1) | is.na(sum(tso$chronData_ages,na.rm=TRUE)) | (sum(!is.na(tso$chronData_ages))<length(tso$chronData_ages)*0.5)){
tso$chronData_table             <- NA
tso$chronData_ageName           <- NA
tso$chronData_ages              <- NA
tso$chronData_ages_12k          <- NA
tso$chronData_agesN_12k         <- NA
tso$chronData_agesMaxGap_12k    <- NA
tso$chronData_agesMedianGap_12k <- NA
}else{
tso$chronData_ages <- tso$chronData_ages[which(!is.na(tso$chronData_ages))]
if(mean(tso$chronData_ages,na.rm=TRUE)<0){
tso$chronData_ages<-tso$chronData_ages*-1 #
}
if(grepl("ka",tso$chronData_table[[tso$chronData_ageName]]$units)){
tso$chronData_ages<-tso$chronData_ages*1000 #d
} else if(max(tso$chronData_ages,na.rm=TRUE)<300){
tso$chronData_ages<-tso$chronData_ages*1000 #d
}
tso$chronData_ages_12k          <- tso$chronData_ages[which(tso$chronData_ages<13000)]
tso$chronData_agesN_12k         <- length(which(diff(tso$chronData_ages_12k)>0))+1
tso$chronData_agesMaxGap_12k    <- max(diff(sort(c(tso$ageMin,tso$chronData_ages_12k,tso$ageMax))))
tso$chronData_agesMedianGap_12k <- median(abs(diff(sort(c(tso$ageMin,tso$chronData_ages_12k,tso$ageMax)))))
}
} else{
tso$chronData_table             <- NA
tso$chronData_ageName           <- NA
tso$chronData_ages              <- NA
tso$chronData_ages_12k          <- NA
tso$chronData_agesN_12k         <- NA
tso$chronData_agesMaxGap_12k    <- NA
tso$chronData_agesMedianGap_12k <- NA
}
lipdData[[var]][[ts]] <- tso
}
}
for (var in names(lipdData)){
for (ts in 1:length(lipdData[[var]])){
#
#Load basic information for each record
#
tso <- lipdData[[var]][[ts]]
#
#Add category information
#
if (var == 'HC'){
archive  <- tso$archiveType
proxy    <- tso$paleoData_proxy
unit     <- tso$paleoData_units
if(is.null(tso$climateInterpretation1_variableDetail)){tso$climateInterpretation1_variableDetail<-'Blank'}
if (is.null(proxy) | is.null(archive)){
tso$Category         <- 'Other'
tso$CategorySpecific <- 'Other (not calibrated)'
} else if (archive == 'Speleothem'){
tso$Category           <- 'Speleothem'
if (proxy == 'd18O' | proxy ==  'd13C'){
tso$CategorySpecific <- paste(archive,' (','δ',substring(proxy, 2),')',sep='')
} else{
tso$CategorySpecific <- 'Speleothem (other)'
}
} else if (tolower(tso$climateInterpretation1_variableDetail) == 'lakelevel@surface'){
tso$Category           <- 'Shoreline'
tso$CategorySpecific   <- 'Shoreline (Lake Level)'
} else if (archive == 'GlacierIce'){
tso$Category           <- 'Glacier Ice'
tso$CategorySpecific   <- 'Glacier Ice (Accumulation)'
} else if (archive == 'LakeSediment' & proxy == 'd18O'){
tso$Category           <- 'Lake Sediment (δ18O)'
tso$CategorySpecific   <- 'Lake Sediment (δ18O)'
} else if (proxy == 'dDwax'){
tso$Category           <- 'Leaf Wax'
tso$CategorySpecific   <- 'Leaf Wax (δD)'
} else if (proxy == 'pollen'){
tso$Category           <- 'Pollen'
if (is.null(unit)){
tso$CategorySpecific <- 'Pollen (not calibrated)'
} else if (grepl('mm/',unit)){
tso$CategorySpecific <- 'Pollen (calibrated)'
} else {
tso$CategorySpecific <- 'Pollen (not calibrated)'
}
} else {
tso$Category           <- 'Other'
if (is.null(unit)){
tso$CategorySpecific <- 'Other (not calibrated)'
} else if (grepl('mm/',unit)){
tso$CategorySpecific <- 'Other (calibrated)'
} else {
tso$CategorySpecific <- 'Other (not calibrated)'
}
}
} else{
tso$Category         <- tso$paleoData_proxyGeneral
tso$CategorySpecific <- tso$paleoData_proxyGeneral
}
#
#Add source
#
if (var == 'HC'){
if (is.null(tso$createdBy)){tso$createdBy <- ''}
if (is.null(tso$originalDataUrl)){tso$originalDataUrl <- ''}
if (is.null(tso$calibration_method)){tso$calibration_method <- ''}
if (is.null(tso$pub1_doi)){tso$pub1_doi <- ''}
if (is.null(tso$pub2_doi)){tso$pub2_doi <- ''}
#
if (grepl('oxfordLakeStatus2Lipd',tso$createdBy)){
tso$Source = 'Oxford Lake Level Database'
}
else if (grepl('paleoDiver2lipd',tso$createdBy)){
tso$Source = 'Liefert and Shuman, 2020'
}
else if (tso$createdBy =='sisal2lipd'){
tso$Source = 'SISALv2'
}
else if (grepl('LegacyClimate2LiPD',tso$createdBy)){
tso$Source = 'Legacy Climate v1.0'
}
else if (tso$originalDataUrl == 'geochange.er.usgs.gov/midden/'){
tso$Source = 'wNA'
}
else if (grepl('/study/30535',tso$originalDataUrl)){
tso$Source = 'wNA'
}
else if (grepl('10.25921/bnxb-1n90',tso$originalDataUrl)){
tso$Source = 'Mid-Latitude Holocene'
}
else if (grepl('/study/15444',tso$originalDataUrl)){
tso$Source = 'Arctic Holocene'
}
else if (grepl('10.5194/essd-12-2261-2020',tso$originalDataUrl) | (substr(tso$dataSetName,1,2) == 'LS')){
tso$Source = 'Iso2k'
}
else if (grepl('10.25921/4RY2-G808',tso$originalDataUrl) | grepl('/study/27330',tso$originalDataUrl)){
tso$Source = 'Temp12k'
} else{tso$Source = 'Other'}
} else{tso$Source <- 'Temp12k'}
#
lipdData[[var]][[ts]] <- tso
}
}
print(paste("Temp:",length(lipdData$T)))  #1319
print(paste("HC:",  length(lipdData$HC))) #819
saveRDS(lipdData, file.path(wd,'Data','Proxy','lipdData.rds'))
for (var in names(lipdData)){
lipdTSO <- lipdData[[var]]
proxyDf <- tibble(dataset       = pullTsVariable(lipdTSO,'dataSetName'),
tsid          = pullTsVariable(lipdTSO,'paleoData_TSid'),
longitude     = pullTsVariable(lipdTSO,'geo_longitude'),
latitude      = pullTsVariable(lipdTSO,'geo_latitude'),
ipccReg       = pullTsVariable(lipdTSO,'geo_ipccRegion'),
archive       = pullTsVariable(lipdTSO,'archiveType'),
proxy         = pullTsVariable(lipdTSO,'paleoData_proxy'),
Category      = pullTsVariable(lipdTSO,'Category'),
CategorySpec  = pullTsVariable(lipdTSO,'CategorySpecific'),
minAge        = pullTsVariable(lipdTSO,'ageMin'),
maxAge        = pullTsVariable(lipdTSO,'ageMax'),
ageRange      = pullTsVariable(lipdTSO,'ageRange'),
ageRes        = pullTsVariable(lipdTSO,'ageRes'),
ageResPlus    = pullTsVariable(lipdTSO,'ageResPlus'),
season        = pullTsVariable(lipdTSO,'climateInterpretation1_seasonalityGeneral'),
climInterp    = pullTsVariable(lipdTSO,'climateInterpretation1_variable'),
source        = pullTsVariable(lipdTSO,'Source'),
direction     = pullTsVariable(lipdTSO,'climateInterpretation1_interpDirection'),
ka_0.5        = rep(NA, length(lipdTSO)),
ka_4          = rep(NA, length(lipdTSO)),
ka_6          = rep(NA, length(lipdTSO)),
ka_8          = rep(NA, length(lipdTSO)),
ka_10         = rep(NA, length(lipdTSO)),
maxValAge     = rep(NA, length(lipdTSO)),
minValAge     = rep(NA, length(lipdTSO)),
)
#
if (var=='HC'){
proxyDf$ageCtrlN      = pullTsVariable(lipdTSO,'chronData_agesN_12k')
proxyDf$ageCtrlMax    = pullTsVariable(lipdTSO,'chronData_agesMaxGap_12k')
proxyDf$ageCtrlMedian = pullTsVariable(lipdTSO,'chronData_agesMedianGap_12k')
}
#Calculate timeslice means
for (tso in lipdTSO){
i = which(proxyDf$tsid == tso$paleoData_TSid)
vals = tso$paleoData_values[which(between(tso$age,0,12000))]
ages =              tso$age[which(between(tso$age,0,12000))]
for (ka in c(0.5,seq(4,10,2))){
bounds <- which(between(ages, 1000*ka-500, 1000*ka+500))
proxyDf[i,paste('ka',ka,sep='_')] <- round(mean(vals[bounds],na.rm=TRUE),3)
}
if (!is.na(proxyDf[i,'direction'])){
if (proxyDf[i,'direction']=='negative'){vals  <- vals*-1
}
}
proxyDf[i,'maxValAge'] <- mean(ages[which(vals==max(vals,na.rm=TRUE))])
proxyDf[i,'minValAge'] <- mean(ages[which(vals==min(vals,na.rm=TRUE))])
}
write.csv(proxyDf,file=file.path(wd,'Data','Proxy',paste('proxyMetadata_',var,'.csv',sep='')))
}
source("/Volumes/GoogleDrive/My Drive/zResearch/Manuscript/2021_HoloceneHydroclimate/2021_HoloceneHydroclimate/Notebooks/2_Analysis/Composite.R", echo=TRUE)
wd  <- '/Volumes/GoogleDrive/My Drive/zResearch/Manuscript/2021_HoloceneHydroclimate/2021_HoloceneHydroclimate' #
var  <- 'HC'
save <- FALSE
saveDir <- file.path(wd,'Data','RegionComposites',var)
lipdData <- readRDS(file.path(wd,'Data','Proxy','LiPD','lipdData.rds'))[[var]]
lipdTSO  <- lipdData[-which(pullTsVariable(lipdData,"climateInterpretation1_seasonalityGeneral") %in% c('winter+','summer','Summer+','Winter+'))]
if(var == 'T'){
lipdTSO <- filterTs(lipdTSO,'paleoData_units == degC')
lipdTSO <- filterTs(lipdTSO,'paleoData_datum == abs')
std <- FALSE      #Use calibrated data so no need to normalize variance
} else{std <- TRUE} #Normalize variance because data recorded with different units
nens          <- 10     #Ensemble numbers (lower = faster)
binsize       <- 100     #years (median resolution = 107yrs)
ageMin        <- 0       #age BP
ageMax        <- 12400   #age BP
searchDur     <- 3500    #yrs (for 3 lake deposit data points)
nThresh       <- 6       #minimum no. of records, else skip
#Set bin vectors
binvec   <- seq(ageMin-binsize/2, to = ageMax+binsize/2, by = binsize)
binYears <- rowMeans(cbind(binvec[-1],binvec[-length(binvec)]))
#ID regions to reconstruct based on number of records (nThresh)
regNames <- data.frame(name=pullTsVariable(lipdTSO,'geo_ipccRegion')) %>%
group_by(name) %>%
summarise(n = n()) %>%
filter(n >= nThresh)
regNames <- c(as.character(regNames$name),'EAN','SSA') #Add 2 SH regions with fewer records to gain global coverage
#Set up data to add once regional composite is calculated
compositeEnsemble <- vector(mode='list')
medianCompositeTS <- data_frame(time=binYears[1:which(binYears==12000)])
sample(seq(1,length(lipdReg)))
?sample
sample(seq(1,length(regN)),regN*0.8)
regN <- length(lipdReg)
nens          <- 10     #Ensemble numbers (lower = faster)
binsize       <- 100     #years (median resolution = 107yrs)
ageMin        <- 0       #age BP
ageMax        <- 12400   #age BP
searchDur     <- 3500    #yrs (for 3 lake deposit data points)
nThresh       <- 6       #minimum no. of records, else skip
#Set bin vectors
binvec   <- seq(ageMin-binsize/2, to = ageMax+binsize/2, by = binsize)
binYears <- rowMeans(cbind(binvec[-1],binvec[-length(binvec)]))
#ID regions to reconstruct based on number of records (nThresh)
regNames <- data.frame(name=pullTsVariable(lipdTSO,'geo_ipccRegion')) %>%
group_by(name) %>%
summarise(n = n()) %>%
filter(n >= nThresh)
regNames <- c(as.character(regNames$name),'EAN','SSA') #Add 2 SH regions with fewer records to gain global coverage
#Set up data to add once regional composite is calculated
compositeEnsemble <- vector(mode='list')
medianCompositeTS <- data_frame(time=binYears[1:which(binYears==12000)])
reg<-'EAS'
lipdReg  <- filterTs(lipdTSO,paste('geo_ipccRegion ==',reg))
for (i in 1:length(lipdReg)){
if (lipdReg[[i]]$climateInterpretation1_interpDirection == 'negative'){
lipdReg[[i]]$paleoData_values <- lipdReg[[i]]$paleoData_values*-1
}
}
regN <- length(lipdReg)
set.seed(5) #Reproducibility
View(lipdReg[[c(1,2)]])
View(lipdReg[c(1,2)])
round(regN*0.8)
round(6*0.8)
round(6*0.75)
round(6*0.7)
round(6*0.66)
round(6*0.75)
round(4*0.75)
round(4*0.8)
round(3*0.8)
round(regN*0.8)
sample(seq(1,regN),max(round(regN*0.8),3))
sample(seq(1,regN),max(round(regN*0.8),3),replace=TRUE)
View(lipdReg[sample(seq(1,regN),max(round(regN*0.8),3))])
reg<-'EAS'
lipdReg  <- filterTs(lipdTSO,paste('geo_ipccRegion ==',reg))
for (i in 1:length(lipdReg)){
if (lipdReg[[i]]$climateInterpretation1_interpDirection == 'negative'){
lipdReg[[i]]$paleoData_values <- lipdReg[[i]]$paleoData_values*-1
}
}
regN <- length(lipdReg)
set.seed(5) #Reproducibility
ensOut <- foreach(i = 1:nens) %dopar% {
tc <- compositeEnsembles(fTS                  = lipdReg[sample(seq(1,regN),max(round(regN*0.8),3))],
binvec               = binvec,
stanFun              = standardizeMeanIteratively,
binFun               = simpleBinTs,
ageVar               = "age",
alignInterpDirection = FALSE,
spread               = TRUE,
duration             = searchDur,
searchRange          = c(1000,10000),
normalizeVariance    = std,
minN                 = 3)
return(list(composite = tc$composite,count = tc$count))
}
View(ensOut)
ensOut <- foreach(i = 1:nens) %dopar% {
tc <- compositeEnsembles(fTS                  = lipdReg[sample(seq(1,regN),max(round(regN*0.8),3))],
binvec               = binvec,
stanFun              = standardizeMeanIteratively,
binFun               = simpleBinTs,
ageVar               = "age",
alignInterpDirection = FALSE,
spread               = TRUE,
duration             = 9000,
searchRange          = c(1000,10000),
normalizeVariance    = FALSE,
minN                 = 3)
return(list(composite = tc$composite,count = tc$count))
}
View(ensOut)
ensOut[[2]][["count"]]
ensOut[[1]][["count"]]
?compositeEnsembles
lipdReg  <- filterTs(lipdTSO,paste('geo_ipccRegion ==',reg))
for (i in 1:length(lipdReg)){
if (lipdReg[[i]]$climateInterpretation1_interpDirection == 'negative'){
lipdReg[[i]]$paleoData_values <- lipdReg[[i]]$paleoData_values*-1
}
}
regN <- length(lipdReg)
set.seed(5) #Reproducibility
ensOut <- foreach(i = 1:nens) %dopar% {
tc <- compositeEnsembles(fTS                  = lipdReg[sample(seq(1,regN),max(round(regN*0.8),3))],
binvec               = binvec,
stanFun              = standardizeMeanIteratively,
binFun               = simpleBinTs,
ageVar               = "age",
alignInterpDirection = FALSE,
spread               = TRUE,
duration             = searchDur,
searchRange          = c(1000,10000),
normalizeVariance    = std,
minN                 = 3)
return(list(composite = tc$composite,count = tc$count))
}
regionComposite           <- as.matrix(purrr::map_dfc(ensOut,magrittr::extract,"composite"))
rownames(regionComposite) <- binYears
regionComposite           <- regionComposite[1:which(binYears==12000),]
compositeEnsemble[[reg]]  <- regionComposite
medianCompositeTS[[reg]]  <- apply(regionComposite,1,median,na.rm=TRUE)
#plot region to confirm that everything looks good
plotTimeseriesEnsRibbons(X = binYears[1:which(binYears==12000)],Y = compositeEnsemble[[reg]])+
scale_x_continuous(name = "age (yr BP)",         oob = scales::squish)+
scale_y_continuous(name = "Standardized Anomaly",oob = scales::squish)+
theme_bw()+
ggtitle(paste(reg,"Composite Ensemble"))
#plot region to confirm that everything looks good
plotTimeseriesEnsRibbons(X = binYears[1:which(binYears==12000)],Y = compositeEnsemble[[reg]])+
scale_x_reverse(name = "age (yr BP)",         oob = scales::squish)+
scale_y_continuous(name = "Standardized Anomaly",oob = scales::squish)+
theme_bw()+
ggtitle(paste(reg,"Composite Ensemble"))
lipdReg  <- filterTs(lipdTSO,paste('geo_ipccRegion ==',reg))
regN <- length(lipdReg)
set.seed(5) #Reproducibility
ensOut <- foreach(i = 1:nens) %dopar% {
tc <- compositeEnsembles(fTS                  = lipdReg[sample(seq(1,regN),max(round(regN*0.8),3))],
binvec               = binvec,
stanFun              = standardizeMeanIteratively,
binFun               = simpleBinTs,
ageVar               = "age",
alignInterpDirection = TRUE,
spread               = TRUE,
duration             = searchDur,
searchRange          = c(1000,10000),
normalizeVariance    = std,
minN                 = 3)
return(list(composite = tc$composite,count = tc$count))
}
regionComposite           <- as.matrix(purrr::map_dfc(ensOut,magrittr::extract,"composite"))
rownames(regionComposite) <- binYears
regionComposite           <- regionComposite[1:which(binYears==12000),]
compositeEnsemble[[reg]]  <- regionComposite
medianCompositeTS[[reg]]  <- apply(regionComposite,1,median,na.rm=TRUE)
#plot region to confirm that everything looks good
plotTimeseriesEnsRibbons(X = binYears[1:which(binYears==12000)],Y = compositeEnsemble[[reg]])+
scale_x_reverse(name = "age (yr BP)",         oob = scales::squish)+
scale_y_continuous(name = "Standardized Anomaly",oob = scales::squish)+
theme_bw()+
ggtitle(paste(reg,"Composite Ensemble"))
lipdReg  <- filterTs(lipdTSO,paste('geo_ipccRegion ==',reg))
regN <- length(lipdReg)
set.seed(5) #Reproducibility
ensOut <- foreach(i = 1:nens) %dopar% {
tc <- compositeEnsembles(fTS                  = lipdReg[sample(seq(1,regN),max(round(regN*0.8),3))],
binvec               = binvec,
stanFun              = standardizeMeanIteratively,
binFun               = simpleBinTs,
ageVar               = "age",
alignInterpDirection = FALSE,
spread               = TRUE,
duration             = searchDur,
searchRange          = c(1000,10000),
normalizeVariance    = std,
minN                 = 3)
return(list(composite = tc$composite,count = tc$count))
}
regionComposite           <- as.matrix(purrr::map_dfc(ensOut,magrittr::extract,"composite"))
rownames(regionComposite) <- binYears
regionComposite           <- regionComposite[1:which(binYears==12000),]
compositeEnsemble[[reg]]  <- regionComposite
medianCompositeTS[[reg]]  <- apply(regionComposite,1,median,na.rm=TRUE)
#plot region to confirm that everything looks good
plotTimeseriesEnsRibbons(X = binYears[1:which(binYears==12000)],Y = compositeEnsemble[[reg]])+
scale_x_reverse(name = "age (yr BP)",         oob = scales::squish)+
scale_y_continuous(name = "Standardized Anomaly",oob = scales::squish)+
theme_bw()+
ggtitle(paste(reg,"Composite Ensemble"))
lipdReg  <- filterTs(lipdTSO,paste('geo_ipccRegion ==',reg))
regN     <- length(lipdReg)
set.seed(5) #Reproducibility
ensOut <- foreach(i = 1:nens) %dopar% {
tc <- compositeEnsembles(fTS                  = lipdReg[sample(seq(1,regN),max(round(regN*0.8),3))],
binvec               = binvec,
stanFun              = standardizeMeanIteratively,
binFun               = simpleBinTs,
ageVar               = "age",
alignInterpDirection = TRUE,
spread               = TRUE,
duration             = searchDur,
searchRange          = c(1000,10000),
normalizeVariance    = std,
minN                 = 3)
return(list(composite = tc$composite,count = tc$count))
}
regionComposite           <- as.matrix(purrr::map_dfc(ensOut,magrittr::extract,"composite"))
rownames(regionComposite) <- binYears
regionComposite           <- regionComposite[1:which(binYears==12000),]
compositeEnsemble[[reg]]  <- regionComposite
medianCompositeTS[[reg]]  <- apply(regionComposite,1,median,na.rm=TRUE)
#plot region to confirm that everything looks good
plotTimeseriesEnsRibbons(X = binYears[1:which(binYears==12000)],Y = compositeEnsemble[[reg]])+
scale_x_reverse(name = "age (yr BP)",         oob = scales::squish)+
scale_y_continuous(name = "Standardized Anomaly",oob = scales::squish)+
theme_bw()+
ggtitle(paste(reg,"Composite Ensemble"))
